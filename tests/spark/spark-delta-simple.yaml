apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-delta-simple
  namespace: default
spec:
  type: Scala
  mode: cluster
  image: ghcr.io/tpomavil46/spark-s3-delta-iceberg:4.0.1
  imagePullPolicy: Always
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: local:///opt/spark/examples/jars/spark-examples_2.13-4.0.0.jar
  arguments:
    - "100"
  sparkVersion: "4.0.0"
  restartPolicy:
    type: Never
  sparkConf:
    # Test Delta Lake is loaded
    spark.sql.extensions: "io.delta.sql.DeltaSparkSessionExtension"
    spark.sql.catalog.spark_catalog: "org.apache.spark.sql.delta.catalog.DeltaCatalog"
    spark.eventLog.enabled: "true"
    spark.eventLog.dir: "s3a://spark-logs/"
    spark.hadoop.fs.s3a.endpoint: "http://172.16.0.20:9000"
    spark.hadoop.fs.s3a.path.style.access: "true"
    spark.hadoop.fs.s3a.connection.ssl.enabled: "false"
    spark.hadoop.fs.s3a.aws.credentials.provider: "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
  driver:
    cores: 1
    coreRequest: "100m"
    memory: "512m"
    serviceAccount: spark-operator-spark
    envSecretKeyRefs:
      AWS_ACCESS_KEY_ID:
        name: spark-minio
        key: access-key
      AWS_SECRET_ACCESS_KEY:
        name: spark-minio
        key: secret-key
  executor:
    cores: 1
    coreRequest: "100m"
    instances: 2
    memory: "512m"
    envSecretKeyRefs:
      AWS_ACCESS_KEY_ID:
        name: spark-minio
        key: access-key
      AWS_SECRET_ACCESS_KEY:
        name: spark-minio
        key: secret-key